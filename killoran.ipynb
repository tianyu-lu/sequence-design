{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/global/homes/d/dbrookes/design_icml/')\n",
    "import itertools\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras import layers, initializers\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from seqtools import SequenceTools as ST\n",
    "from gfp_gp import SequenceGP\n",
    "from util import AA, AA_IDX\n",
    "from util import build_vae\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gan import WGAN\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from util import one_hot_encode_aa, partition_data, get_balaji_predictions, get_samples, get_argmax\n",
    "from util import convert_idx_array_to_aas, build_pred_vae_model, get_experimental_X_y\n",
    "from util import get_gfp_X_y_aa\n",
    "from losses import neg_log_likelihood\n",
    "import json\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                 steps=10000, epsilon1=10**-5, epsilon2=1, noise_std=10**-5,\n",
    "                 LD=100, verbose=False, adam=False):\n",
    "    L = X_train.shape[1]\n",
    "    \n",
    "    G = vae.decoder_\n",
    "    f = oracles\n",
    "    \n",
    "    sess = K.get_session()\n",
    "    zt = K.tf.Variable(np.random.normal(size=[1, LD]), dtype='float32')\n",
    "    pred_input = K.tf.Variable(np.zeros((1, L, X_train.shape[2])), dtype='float32')\n",
    "    gen_output = G(zt)\n",
    "    prior = tfd.Normal(0, 1)\n",
    "    p_z = prior.log_prob(zt)\n",
    "    predictions = K.tf.reduce_mean([f[i](pred_input)[0, 0] for i in range(len(f))])\n",
    "    update_pred_input = K.tf.assign(pred_input, gen_output)\n",
    "    dfdx = K.tf.gradients(ys=-predictions, xs=pred_input)[0]\n",
    "    dfdz = K.tf.gradients(gen_output, zt, grad_ys=dfdx)[0]\n",
    "    dpz = K.tf.gradients(p_z, zt)[0]\n",
    "    \n",
    "    noise = K.tf.random_normal(shape=[1, LD], stddev=noise_std)\n",
    "    eps1 = K.tf.Variable(epsilon1, trainable=False)\n",
    "    eps2 = K.tf.Variable(epsilon2, trainable=False)\n",
    "    if adam:\n",
    "        optimizer = K.tf.train.AdamOptimizer(learning_rate=epsilon2)\n",
    "        step = dfdz + noise\n",
    "    else:\n",
    "        optimizer = K.tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "        step = eps1 * dpz + eps2 * dfdz + noise\n",
    "    \n",
    "    design_op = optimizer.apply_gradients([(step, zt)])\n",
    "    adam_initializers = [var.initializer for var in K.tf.global_variables() if 'Adam' in var.name or 'beta' in var.name]\n",
    "    sess.run(adam_initializers)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(zt.initializer)\n",
    "    sess.run(eps1.initializer)\n",
    "    sess.run(eps2.initializer)\n",
    "\n",
    "    s = sess.run(K.tf.shape(zt))\n",
    "    sess.run(update_pred_input, {zt: np.random.normal(size=s)})\n",
    "    z_0 = sess.run([zt])\n",
    "    results = np.zeros((steps, 2))\n",
    "    xt_prev = None\n",
    "    for t in range(steps):\n",
    "        xt0, _, = sess.run([gen_output, design_op], {eps1: epsilon1, eps2:epsilon2})\n",
    "        pred_in, preds = sess.run([update_pred_input, predictions])\n",
    "        xt = get_argmax(xt0)\n",
    "        ft = get_balaji_predictions(oracles, xt)[0][0]\n",
    "        xt_seq = np.argmax(xt, axis=-1)\n",
    "        if xt_prev is None or not np.all(xt_seq == xt_prev):\n",
    "            xt_prev = xt_seq\n",
    "            gt = ground_truth.predict(xt_seq)[:, 0][0]\n",
    "        else:\n",
    "            gt = results[t-1, 1]\n",
    "        results[t, 0] = ft\n",
    "        results[t, 1] = gt\n",
    "    return results, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experimental_gans():\n",
    "    TRAIN_SIZE = 5000\n",
    "    train_size_str = \"%ik\" % (TRAIN_SIZE/1000)\n",
    "    for it in range(1):  # Can only use the first oracle and training set....b/c it can't take an ensemble\n",
    "        RANDOM_STATE = it + 1\n",
    "        X_train, y_train, _  = get_experimental_X_y(random_state=RANDOM_STATE, train_size=TRAIN_SIZE)\n",
    "        \n",
    "        L = X_train.shape[1]\n",
    "        LD=100\n",
    "        gan = WGAN(input_shape=(L, X_train.shape[2],), latent_dim=LD, gumbel=False)\n",
    "\n",
    "        gan.train(X_train,\n",
    "                 batch_size=1000,\n",
    "                 epochs=100,\n",
    "                 verbose=2\n",
    "                 ) \n",
    "\n",
    "        suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "        gan.generator.save_weights(\"models/killoran_gan_geneorator_weights%s.h5\" % suffix)\n",
    "        gan.critic.save_weights(\"models/killoran_gan_critic_weights%s.h5\" % suffix)\n",
    "        gan.combined.save_weights(\"models/killoran_gan_combined_weights%s.h5\" % suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_killoran(killoran=True):\n",
    "    TRAIN_SIZE = 5000\n",
    "    train_size_str = \"%ik\" % (TRAIN_SIZE/1000)\n",
    "    for i in range(3):\n",
    "        RANDOM_STATE = i+1\n",
    "        print(RANDOM_STATE)\n",
    "        num_models = [1, 5, 20][i]\n",
    "        X_train, _, _  = get_experimental_X_y(random_state=RANDOM_STATE, train_size=TRAIN_SIZE)\n",
    "\n",
    "        LD=20\n",
    "        L = X_train.shape[1]\n",
    "        \n",
    "        vae_suffix = '_%s_%i' % (train_size_str, RANDOM_STATE)\n",
    "        \n",
    "        ground_truth = SequenceGP(load=True, load_prefix=\"data/gfp_gp\")\n",
    "        loss = neg_log_likelihood\n",
    "        get_custom_objects().update({\"neg_log_likelihood\": loss})\n",
    "        oracle_suffix = '_%s_%i_%i' % (train_size_str, num_models, RANDOM_STATE)\n",
    "        \n",
    "        \n",
    "        sess = tf.Session(graph=tf.get_default_graph())\n",
    "        K.set_session(sess)\n",
    "        vae = build_vae(latent_dim=20,\n",
    "                  n_tokens=20, \n",
    "                  seq_length=X_train.shape[1],\n",
    "                  enc1_units=50)\n",
    "        vae.encoder_.load_weights(\"models/vae_0_encoder_weights%s.h5\" % vae_suffix)\n",
    "        vae.decoder_.load_weights(\"models/vae_0_decoder_weights%s.h5\"% vae_suffix)\n",
    "        vae.vae_.load_weights(\"models/vae_0_vae_weights%s.h5\"% vae_suffix)\n",
    "        \n",
    "        oracles = [load_model(\"models/oracle_%i%s.h5\" % (i, oracle_suffix)) for i in range(num_models)]\n",
    "        if not killoran:\n",
    "            results, test_max = killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                                   steps=30000, epsilon1=1e-5, epsilon2=1.,  \n",
    "                                   noise_std=1e-5,\n",
    "                                   LD=20, verbose=False, adam=False)\n",
    "            \n",
    "            np.save(\"results/mala_results_%s_%i.npy\" % (train_size_str, RANDOM_STATE), results)\n",
    "            suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "            with open('results/%s_max%s.json'% ('mala', suffix), 'w') as outfile:\n",
    "                json.dump(test_max, outfile)\n",
    "                \n",
    "        else:\n",
    "            results, test_max = killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                                             steps=10000, epsilon1=0., epsilon2=0.1,  \n",
    "                                             noise_std=1e-6,\n",
    "                                             LD=20, verbose=False, adam=True)\n",
    "            np.save(\"results/killoran_may_results_%s_%i.npy\" % (train_size_str, RANDOM_STATE), results)\n",
    "            suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "            with open('results/%s_max%s.json'% ('killoran', suffix), 'w') as outfile:\n",
    "                json.dump(test_max, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From /global/homes/d/dbrookes/.conda/envs/myconda2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /global/homes/d/dbrookes/.conda/envs/myconda2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /global/homes/d/dbrookes/.conda/envs/myconda2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# train_experimental_gans()\n",
    "run_killoran(killoran=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyConda2",
   "language": "python",
   "name": "myconda2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
